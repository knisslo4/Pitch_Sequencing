{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"CUDA Available: \", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STATCAST_DB = mysql.connector.connect(\n",
    "  host=host,\n",
    "  user=user,\n",
    "  password=password,\n",
    "  database=database\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MICHAEL_LORENZEN_2023 = \"\"\"SELECT player_name, stand, pitch_type_condensed, game_pk, at_bat_number, pitch_number \n",
    "FROM sc_raw \n",
    "WHERE pitcher = '547179' AND game_year = '2023'\n",
    "ORDER BY game_pk, at_bat_number, pitch_number;\"\"\"\n",
    "\n",
    "MICHAEL_LORENZEN_2023 = pd.read_sql_query(MICHAEL_LORENZEN_2023, STATCAST_DB)\n",
    "'''\n",
    "\n",
    "# print(MICHAEL_LORENZEN_2023)\n",
    "# MICHAEL_LORENZEN_2023.to_csv('MICHAEL_LORENZEN_2023.csv', index=False)\n",
    "\n",
    "MICHAEL_LORENZEN_2023 = pd.read_csv('MICHAEL_LORENZEN_2023.csv')\n",
    "MICHAEL_LORENZEN_2023.rename(columns={'pitch_type_condensed': 'pitch_type'}, inplace=True)\n",
    "\n",
    "pitch_type_dummies = pd.get_dummies(MICHAEL_LORENZEN_2023['pitch_type'])\n",
    "MICHAEL_LORENZEN_2023_PREP = pd.concat([MICHAEL_LORENZEN_2023, pitch_type_dummies], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "MICHAEL_LORENZEN_2023_PREP['pitch_number'] = scaler.fit_transform(MICHAEL_LORENZEN_2023_PREP[['pitch_number']])\n",
    "\n",
    "# print(MICHAEL_LORENZEN_2023_PREP)\n",
    "# MICHAEL_LORENZEN_2023_PREP.to_csv('MICHAEL_LORENZEN_2023_PREP.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pitch_types = MICHAEL_LORENZEN_2023_PREP['pitch_type'].unique()\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_pitch_types)\n",
    "\n",
    "grouped = MICHAEL_LORENZEN_2023_PREP.groupby(['game_pk', 'at_bat_number'])\n",
    "grouped_sequences = []\n",
    "labels = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        sequences = group.iloc[:-1][['CB', 'CH', 'CT', 'FAHCK', 'FF', 'SI', 'SL']].values.tolist()\n",
    "        grouped_sequences.append(sequences)\n",
    "        \n",
    "        label = group.iloc[-1]['pitch_type']\n",
    "        encoded_label = label_encoder.transform([label])[0]\n",
    "        labels.append(encoded_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_tensors = [torch.tensor(seq, dtype=torch.float) for seq in grouped_sequences]\n",
    "'''\n",
    "if not sequences:\n",
    "    raise ValueError(\"All sequences are empty or no sequence is available.\")\n",
    "    \n",
    "# Assuming sequences is not empty and contains tensors\n",
    "try:\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "except RuntimeError as e:\n",
    "    print(f\"RuntimeError encountered: {e}\")\n",
    "    print(\"Checking sequence lengths and types...\")\n",
    "    for i, seq in enumerate(sequences):\n",
    "        print(f\"Sequence {i} length: {len(seq)}, type: {seq.dtype}\")\n",
    "    raise\n",
    "'''\n",
    "# print(sequences)\n",
    "padded_sequences = pad_sequence(sequences_tensors, batch_first=True, padding_value=0)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PitchDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sequence, label\n",
    "    \n",
    "dataset = PitchDataset(padded_sequences, labels_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PitchPredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(PitchPredictionModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x.size(0))\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        c0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return [t for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 7\n",
    "hidden_dim = 128\n",
    "output_dim = len(label_encoder.classes_)\n",
    "n_layers = 2\n",
    "\n",
    "model = PitchPredictionModel(input_dim, hidden_dim, output_dim, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming padded_sequences and labels_tensor are your full dataset\n",
    "# First, split into a combined training+validation set and a separate test set\n",
    "train_val_seqs, test_seqs, train_val_labels, test_labels = train_test_split(\n",
    "    padded_sequences, labels_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training+validation set into separate training and validation sets\n",
    "train_seqs, valid_seqs, train_labels, valid_labels = train_test_split(\n",
    "    train_val_seqs, train_val_labels, test_size=0.25, random_state=42)  # Adjust test_size as needed\n",
    "\n",
    "# Now, train_seqs and train_labels are for training, valid_seqs and valid_labels are for validation,\n",
    "# and test_seqs and test_labels are reserved for final testing.\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PitchDataset(train_seqs, train_labels)\n",
    "valid_dataset = PitchDataset(valid_seqs, valid_labels)\n",
    "test_dataset = PitchDataset(test_seqs, test_labels)  # Test dataset\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Test DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    total_loss = 0\n",
    "    \n",
    "    for sequences, labels in train_loader:\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(sequences)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in valid_loader:\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(valid_loader)\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {total_loss/len(train_loader)}, Validation Loss: {val_loss}')\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # Reset counter\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Validation loss has not improved for {patience_counter} epoch(s).')\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(\"Stopping early due to no improvement in validation loss.\")\n",
    "        break\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PitchPredictionModel(\n",
       "  (lstm): LSTM(7, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PitchPredictionModel(input_dim, hidden_dim, output_dim, n_layers)  # Initialize the model\n",
    "model.load_state_dict(torch.load('best_model.pth'))  # Load the saved weights\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 37.61%\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  1]\n",
      " [ 0 20  0  0  2  0  8]\n",
      " [ 0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0 13  0  0  3  0 15]\n",
      " [ 0  2  0  0  0  0 16]\n",
      " [ 0 10  0  0  2  0 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming you have a DataLoader for your test data named 'test_loader'\n",
    "predictions, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for sequences, labels in test_loader:  # Replace 'test_loader' with 'valid_loader' if you don't have a separate test set\n",
    "        outputs = model(sequences)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.view(-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Optionally, compute and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
